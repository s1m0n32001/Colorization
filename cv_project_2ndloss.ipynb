{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "yHwDZBBc-TLH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image colorization using CNN\n",
        "\n",
        "Cose da fare:\n",
        "\n",
        "\n",
        "Extra\n",
        " - Cercare un dataset con risoluzione un po' più alta?\n",
        " - Implementare sia la loss function base (MSE) che quella \"speciale\" del paper\n",
        "\n",
        "\n",
        " Che rete usiamo?\n",
        "  - Resnet: funziona ma è uguale identica a quella su github, meglio cambiarla?\n",
        "  - VGG16: troppo lenta, il training impiega quasi 40 min per un'epoca\n",
        "\n"
      ],
      "metadata": {
        "id": "bhF7c6FetF5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kornia #Library to convert from RGB to LAB"
      ],
      "metadata": {
        "id": "UOXelm1TxSkk",
        "outputId": "4a8ea24b-da66-4606-bab7-79efae966a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kornia in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (23.2)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJUv1ql-3P3r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import kornia\n",
        "import pickle\n",
        "from statistics import mean\n",
        "\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "import torch.utils.data as data_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import rgb2lab"
      ],
      "metadata": {
        "id": "JA8SP46rnYlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\") #to use gpu"
      ],
      "metadata": {
        "id": "ZM2EQKIBVknO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and preprocess dataset (CIFAR10)\n",
        "In this section, we import the dataset and process it properly. We discard the labels (we don't care about them since our goal is colorization, not classification) and set up a new dataset whose features are the L channel and whose labels are the AB channels. We then set up a Dataloader to process the data in batches.\n"
      ],
      "metadata": {
        "id": "G8spMWtL37SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "587S8fC6ZcuQ",
        "outputId": "ed17ddb2-4937-4f6d-bab7-d4e624cc7389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform to LAB and separate the L and (a,b) channels\n",
        "class RGB_to_LAB:\n",
        "  def __call__(self, sample):\n",
        "    # tensor = kornia.color.rgb_to_lab(sample) # 3 x 32 x 32\n",
        "    tensor = rgb2lab(sample.numpy(), channel_axis=0) # 3 x 32 x 32\n",
        "    tensor = torch.tensor(tensor)\n",
        "    l = tensor[0, : , :]\n",
        "    bw = torch.empty([3, 32, 32])\n",
        "    bw[0, : , :] = l\n",
        "    bw[1, : , :] = l\n",
        "    bw[2, : , :] = 1\n",
        "    return bw, tensor[1:, :, :]\n",
        "\n",
        "#Function to switch back to rgb\n",
        "def LAB_to_RGB(l_tensor, ab_tensor):\n",
        "  tensor = torch.cat([torch.unsqueeze(l_tensor,0), ab_tensor], dim = 0)\n",
        "  tensor = kornia.color.lab_to_rgb(tensor)\n",
        "  return tensor\n",
        "\n",
        "transform_rgb_lab = RGB_to_LAB()\n",
        "composed = transforms.Compose([transforms.ToTensor(), transform_rgb_lab])\n",
        "# composed = transforms.Compose([transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "YW27cPTCvbJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset --> set download = True if it's the first time you're opening it\n",
        "dataset = CIFAR10(root = \"/content/gdrive/My Drive/CIFAR10\", download = False,\n",
        "                  transform = composed, train = True)"
      ],
      "metadata": {
        "id": "boJxDqZA3_Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove labels from dataset\n",
        "def discard_labels(data):\n",
        "  return([datum[0] for datum in data])\n",
        "\n",
        "dataset = discard_labels(dataset)"
      ],
      "metadata": {
        "id": "mT4A2Pt3wIZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the l and ab channels and store them as tensor\n",
        "\n",
        "# dato = (l, ab)\n",
        "def select_l(data):\n",
        "  return([datum[0] for datum in data])\n",
        "def select_ab(data):\n",
        "  return([datum[1] for datum in data])\n",
        "\n",
        "dataset_l =  select_l(dataset)\n",
        "dataset_ab = select_ab(dataset)\n",
        "\n",
        "#Convert to tensor form --> represents the features as one tensor 4D [index, 3, 32, 32]\n",
        "dataset_l  = torch.cat([torch.unsqueeze(tens, 0) for tens in dataset_l])\n",
        "dataset_ab = torch.cat([torch.unsqueeze(tens, 0) for tens in dataset_ab])"
      ],
      "metadata": {
        "id": "0-fSiYYTzFoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution of (a,b)"
      ],
      "metadata": {
        "id": "u41ryQuB2KLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = dataset_ab[:,0,:,:].reshape(1,-1)\n",
        "x = torch.squeeze(x)"
      ],
      "metadata": {
        "id": "pbNsiktDypS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = dataset_ab[:,0,:,:].reshape(1,-1)\n",
        "a = torch.squeeze(a).numpy()\n",
        "b = dataset_ab[:,1,:,:].reshape(1,-1)\n",
        "b = torch.squeeze(b).numpy()\n",
        "\n",
        "# Define the limits for the x and y axes\n",
        "x_min, x_max = -110, 110\n",
        "y_min, y_max = -110, 110\n",
        "\n",
        "# Compute 2D histogram\n",
        "hist, xedges, yedges = np.histogram2d(a, b, bins=22, range=[[x_min, x_max], [y_min, y_max]])\n",
        "\n",
        "print(xedges)\n",
        "\n",
        "print(len(x), '\\n')\n",
        "print(np.sum(hist), '\\n')\n",
        "print('Diff: ', len(x) - np.sum(hist))\n",
        "\n",
        "hist_log = np.log((hist/np.sum(hist)))\n",
        "\n",
        "# Plot the histogram in logarithmic scale\n",
        "plt.imshow(hist_log, interpolation='nearest', extent=[x_min, x_max, y_max, y_min], origin='lower', aspect='auto')\n",
        "plt.colorbar()\n",
        "plt.xlabel('b')\n",
        "plt.ylabel('a')\n",
        "plt.title('Log(P(a,b))')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "NkLlJCsSx2fw",
        "outputId": "5f02eefe-f223-4f12-f3d8-8bf8b98eb3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-110. -100.  -90.  -80.  -70.  -60.  -50.  -40.  -30.  -20.  -10.    0.\n",
            "   10.   20.   30.   40.   50.   60.   70.   80.   90.  100.  110.]\n",
            "51200000 \n",
            "\n",
            "51200000.0 \n",
            "\n",
            "Diff:  0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-58f412531f82>:19: RuntimeWarning: divide by zero encountered in log\n",
            "  hist_log = np.log((hist/np.sum(hist)))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now want to map each upperleft corner of a nonzero bin to its bin number"
      ],
      "metadata": {
        "id": "FKy2W-bdpl-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = np.sum(np.isfinite(hist_log))\n",
        "print(\"With our dataset we get Q = \", Q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm1hE-1jx2dK",
        "outputId": "c5b5e33e-817c-4f32-a878-0bf9c5868a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With our dataset we get Q =  246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_obj = plt.hist2d(a, b, bins=22, range=[[x_min, x_max], [y_min, y_max]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "LlPG_HCt6qyA",
        "outputId": "18d1a6f5-5b35-4ce6-a969-1c345801eacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Keep track of where the grid points are\n",
        "positions = []\n",
        "indeces = []\n",
        "\n",
        "index = 0\n",
        "\n",
        "for i in range(len(hist_obj[1][:-1])):\n",
        "  for j in range(len(hist_obj[2][:-1])):\n",
        "    if hist_obj[0][i, j] > 0:\n",
        "      positions.append((i,j))\n",
        "      indeces.append(index)\n",
        "      index += 1\n",
        "\n",
        "dictionary = dict(zip(positions, indeces))"
      ],
      "metadata": {
        "id": "KHu3lStZ-ZMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store new dataset"
      ],
      "metadata": {
        "id": "yHwDZBBc-TLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create ground truth Z_label\n",
        "\n",
        "output_tensor = torch.zeros(50000, 1, 32, 32)\n",
        "\n",
        "for image_number in range(dataset_ab.shape[0]):\n",
        "  if image_number % 100 == 0:\n",
        "    print(\"Image_nUmber : \", image_number)\n",
        "  Z_image = np.zeros([1, 32, 32])\n",
        "  image = dataset_ab[image_number, :, :, :]\n",
        "  for i in range(32):\n",
        "    for j in range(32):\n",
        "      couple = tuple(torch.Tensor.tolist(torch.Tensor.int(image[:, i,j] // 10 + 11)))\n",
        "      index = dictionary[couple]\n",
        "      Z_image[0, i, j] = index\n",
        "  output_tensor[image_number, :, :, :] = torch.tensor(Z_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu_xV1pUwlBa",
        "outputId": "b2f9b11f-1979-4886-dedd-6c4f0d6089bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image_nUmber :  0\n",
            "Image_nUmber :  100\n",
            "Image_nUmber :  200\n",
            "Image_nUmber :  300\n",
            "Image_nUmber :  400\n",
            "Image_nUmber :  500\n",
            "Image_nUmber :  600\n",
            "Image_nUmber :  700\n",
            "Image_nUmber :  800\n",
            "Image_nUmber :  900\n",
            "Image_nUmber :  1000\n",
            "Image_nUmber :  1100\n",
            "Image_nUmber :  1200\n",
            "Image_nUmber :  1300\n",
            "Image_nUmber :  1400\n",
            "Image_nUmber :  1500\n",
            "Image_nUmber :  1600\n",
            "Image_nUmber :  1700\n",
            "Image_nUmber :  1800\n",
            "Image_nUmber :  1900\n",
            "Image_nUmber :  2000\n",
            "Image_nUmber :  2100\n",
            "Image_nUmber :  2200\n",
            "Image_nUmber :  2300\n",
            "Image_nUmber :  2400\n",
            "Image_nUmber :  2500\n",
            "Image_nUmber :  2600\n",
            "Image_nUmber :  2700\n",
            "Image_nUmber :  2800\n",
            "Image_nUmber :  2900\n",
            "Image_nUmber :  3000\n",
            "Image_nUmber :  3100\n",
            "Image_nUmber :  3200\n",
            "Image_nUmber :  3300\n",
            "Image_nUmber :  3400\n",
            "Image_nUmber :  3500\n",
            "Image_nUmber :  3600\n",
            "Image_nUmber :  3700\n",
            "Image_nUmber :  3800\n",
            "Image_nUmber :  3900\n",
            "Image_nUmber :  4000\n",
            "Image_nUmber :  4100\n",
            "Image_nUmber :  4200\n",
            "Image_nUmber :  4300\n",
            "Image_nUmber :  4400\n",
            "Image_nUmber :  4500\n",
            "Image_nUmber :  4600\n",
            "Image_nUmber :  4700\n",
            "Image_nUmber :  4800\n",
            "Image_nUmber :  4900\n",
            "Image_nUmber :  5000\n",
            "Image_nUmber :  5100\n",
            "Image_nUmber :  5200\n",
            "Image_nUmber :  5300\n",
            "Image_nUmber :  5400\n",
            "Image_nUmber :  5500\n",
            "Image_nUmber :  5600\n",
            "Image_nUmber :  5700\n",
            "Image_nUmber :  5800\n",
            "Image_nUmber :  5900\n",
            "Image_nUmber :  6000\n",
            "Image_nUmber :  6100\n",
            "Image_nUmber :  6200\n",
            "Image_nUmber :  6300\n",
            "Image_nUmber :  6400\n",
            "Image_nUmber :  6500\n",
            "Image_nUmber :  6600\n",
            "Image_nUmber :  6700\n",
            "Image_nUmber :  6800\n",
            "Image_nUmber :  6900\n",
            "Image_nUmber :  7000\n",
            "Image_nUmber :  7100\n",
            "Image_nUmber :  7200\n",
            "Image_nUmber :  7300\n",
            "Image_nUmber :  7400\n",
            "Image_nUmber :  7500\n",
            "Image_nUmber :  7600\n",
            "Image_nUmber :  7700\n",
            "Image_nUmber :  7800\n",
            "Image_nUmber :  7900\n",
            "Image_nUmber :  8000\n",
            "Image_nUmber :  8100\n",
            "Image_nUmber :  8200\n",
            "Image_nUmber :  8300\n",
            "Image_nUmber :  8400\n",
            "Image_nUmber :  8500\n",
            "Image_nUmber :  8600\n",
            "Image_nUmber :  8700\n",
            "Image_nUmber :  8800\n",
            "Image_nUmber :  8900\n",
            "Image_nUmber :  9000\n",
            "Image_nUmber :  9100\n",
            "Image_nUmber :  9200\n",
            "Image_nUmber :  9300\n",
            "Image_nUmber :  9400\n",
            "Image_nUmber :  9500\n",
            "Image_nUmber :  9600\n",
            "Image_nUmber :  9700\n",
            "Image_nUmber :  9800\n",
            "Image_nUmber :  9900\n",
            "Image_nUmber :  10000\n",
            "Image_nUmber :  10100\n",
            "Image_nUmber :  10200\n",
            "Image_nUmber :  10300\n",
            "Image_nUmber :  10400\n",
            "Image_nUmber :  10500\n",
            "Image_nUmber :  10600\n",
            "Image_nUmber :  10700\n",
            "Image_nUmber :  10800\n",
            "Image_nUmber :  10900\n",
            "Image_nUmber :  11000\n",
            "Image_nUmber :  11100\n",
            "Image_nUmber :  11200\n",
            "Image_nUmber :  11300\n",
            "Image_nUmber :  11400\n",
            "Image_nUmber :  11500\n",
            "Image_nUmber :  11600\n",
            "Image_nUmber :  11700\n",
            "Image_nUmber :  11800\n",
            "Image_nUmber :  11900\n",
            "Image_nUmber :  12000\n",
            "Image_nUmber :  12100\n",
            "Image_nUmber :  12200\n",
            "Image_nUmber :  12300\n",
            "Image_nUmber :  12400\n",
            "Image_nUmber :  12500\n",
            "Image_nUmber :  12600\n",
            "Image_nUmber :  12700\n",
            "Image_nUmber :  12800\n",
            "Image_nUmber :  12900\n",
            "Image_nUmber :  13000\n",
            "Image_nUmber :  13100\n",
            "Image_nUmber :  13200\n",
            "Image_nUmber :  13300\n",
            "Image_nUmber :  13400\n",
            "Image_nUmber :  13500\n",
            "Image_nUmber :  13600\n",
            "Image_nUmber :  13700\n",
            "Image_nUmber :  13800\n",
            "Image_nUmber :  13900\n",
            "Image_nUmber :  14000\n",
            "Image_nUmber :  14100\n",
            "Image_nUmber :  14200\n",
            "Image_nUmber :  14300\n",
            "Image_nUmber :  14400\n",
            "Image_nUmber :  14500\n",
            "Image_nUmber :  14600\n",
            "Image_nUmber :  14700\n",
            "Image_nUmber :  14800\n",
            "Image_nUmber :  14900\n",
            "Image_nUmber :  15000\n",
            "Image_nUmber :  15100\n",
            "Image_nUmber :  15200\n",
            "Image_nUmber :  15300\n",
            "Image_nUmber :  15400\n",
            "Image_nUmber :  15500\n",
            "Image_nUmber :  15600\n",
            "Image_nUmber :  15700\n",
            "Image_nUmber :  15800\n",
            "Image_nUmber :  15900\n",
            "Image_nUmber :  16000\n",
            "Image_nUmber :  16100\n",
            "Image_nUmber :  16200\n",
            "Image_nUmber :  16300\n",
            "Image_nUmber :  16400\n",
            "Image_nUmber :  16500\n",
            "Image_nUmber :  16600\n",
            "Image_nUmber :  16700\n",
            "Image_nUmber :  16800\n",
            "Image_nUmber :  16900\n",
            "Image_nUmber :  17000\n",
            "Image_nUmber :  17100\n",
            "Image_nUmber :  17200\n",
            "Image_nUmber :  17300\n",
            "Image_nUmber :  17400\n",
            "Image_nUmber :  17500\n",
            "Image_nUmber :  17600\n",
            "Image_nUmber :  17700\n",
            "Image_nUmber :  17800\n",
            "Image_nUmber :  17900\n",
            "Image_nUmber :  18000\n",
            "Image_nUmber :  18100\n",
            "Image_nUmber :  18200\n",
            "Image_nUmber :  18300\n",
            "Image_nUmber :  18400\n",
            "Image_nUmber :  18500\n",
            "Image_nUmber :  18600\n",
            "Image_nUmber :  18700\n",
            "Image_nUmber :  18800\n",
            "Image_nUmber :  18900\n",
            "Image_nUmber :  19000\n",
            "Image_nUmber :  19100\n",
            "Image_nUmber :  19200\n",
            "Image_nUmber :  19300\n",
            "Image_nUmber :  19400\n",
            "Image_nUmber :  19500\n",
            "Image_nUmber :  19600\n",
            "Image_nUmber :  19700\n",
            "Image_nUmber :  19800\n",
            "Image_nUmber :  19900\n",
            "Image_nUmber :  20000\n",
            "Image_nUmber :  20100\n",
            "Image_nUmber :  20200\n",
            "Image_nUmber :  20300\n",
            "Image_nUmber :  20400\n",
            "Image_nUmber :  20500\n",
            "Image_nUmber :  20600\n",
            "Image_nUmber :  20700\n",
            "Image_nUmber :  20800\n",
            "Image_nUmber :  20900\n",
            "Image_nUmber :  21000\n",
            "Image_nUmber :  21100\n",
            "Image_nUmber :  21200\n",
            "Image_nUmber :  21300\n",
            "Image_nUmber :  21400\n",
            "Image_nUmber :  21500\n",
            "Image_nUmber :  21600\n",
            "Image_nUmber :  21700\n",
            "Image_nUmber :  21800\n",
            "Image_nUmber :  21900\n",
            "Image_nUmber :  22000\n",
            "Image_nUmber :  22100\n",
            "Image_nUmber :  22200\n",
            "Image_nUmber :  22300\n",
            "Image_nUmber :  22400\n",
            "Image_nUmber :  22500\n",
            "Image_nUmber :  22600\n",
            "Image_nUmber :  22700\n",
            "Image_nUmber :  22800\n",
            "Image_nUmber :  22900\n",
            "Image_nUmber :  23000\n",
            "Image_nUmber :  23100\n",
            "Image_nUmber :  23200\n",
            "Image_nUmber :  23300\n",
            "Image_nUmber :  23400\n",
            "Image_nUmber :  23500\n",
            "Image_nUmber :  23600\n",
            "Image_nUmber :  23700\n",
            "Image_nUmber :  23800\n",
            "Image_nUmber :  23900\n",
            "Image_nUmber :  24000\n",
            "Image_nUmber :  24100\n",
            "Image_nUmber :  24200\n",
            "Image_nUmber :  24300\n",
            "Image_nUmber :  24400\n",
            "Image_nUmber :  24500\n",
            "Image_nUmber :  24600\n",
            "Image_nUmber :  24700\n",
            "Image_nUmber :  24800\n",
            "Image_nUmber :  24900\n",
            "Image_nUmber :  25000\n",
            "Image_nUmber :  25100\n",
            "Image_nUmber :  25200\n",
            "Image_nUmber :  25300\n",
            "Image_nUmber :  25400\n",
            "Image_nUmber :  25500\n",
            "Image_nUmber :  25600\n",
            "Image_nUmber :  25700\n",
            "Image_nUmber :  25800\n",
            "Image_nUmber :  25900\n",
            "Image_nUmber :  26000\n",
            "Image_nUmber :  26100\n",
            "Image_nUmber :  26200\n",
            "Image_nUmber :  26300\n",
            "Image_nUmber :  26400\n",
            "Image_nUmber :  26500\n",
            "Image_nUmber :  26600\n",
            "Image_nUmber :  26700\n",
            "Image_nUmber :  26800\n",
            "Image_nUmber :  26900\n",
            "Image_nUmber :  27000\n",
            "Image_nUmber :  27100\n",
            "Image_nUmber :  27200\n",
            "Image_nUmber :  27300\n",
            "Image_nUmber :  27400\n",
            "Image_nUmber :  27500\n",
            "Image_nUmber :  27600\n",
            "Image_nUmber :  27700\n",
            "Image_nUmber :  27800\n",
            "Image_nUmber :  27900\n",
            "Image_nUmber :  28000\n",
            "Image_nUmber :  28100\n",
            "Image_nUmber :  28200\n",
            "Image_nUmber :  28300\n",
            "Image_nUmber :  28400\n",
            "Image_nUmber :  28500\n",
            "Image_nUmber :  28600\n",
            "Image_nUmber :  28700\n",
            "Image_nUmber :  28800\n",
            "Image_nUmber :  28900\n",
            "Image_nUmber :  29000\n",
            "Image_nUmber :  29100\n",
            "Image_nUmber :  29200\n",
            "Image_nUmber :  29300\n",
            "Image_nUmber :  29400\n",
            "Image_nUmber :  29500\n",
            "Image_nUmber :  29600\n",
            "Image_nUmber :  29700\n",
            "Image_nUmber :  29800\n",
            "Image_nUmber :  29900\n",
            "Image_nUmber :  30000\n",
            "Image_nUmber :  30100\n",
            "Image_nUmber :  30200\n",
            "Image_nUmber :  30300\n",
            "Image_nUmber :  30400\n",
            "Image_nUmber :  30500\n",
            "Image_nUmber :  30600\n",
            "Image_nUmber :  30700\n",
            "Image_nUmber :  30800\n",
            "Image_nUmber :  30900\n",
            "Image_nUmber :  31000\n",
            "Image_nUmber :  31100\n",
            "Image_nUmber :  31200\n",
            "Image_nUmber :  31300\n",
            "Image_nUmber :  31400\n",
            "Image_nUmber :  31500\n",
            "Image_nUmber :  31600\n",
            "Image_nUmber :  31700\n",
            "Image_nUmber :  31800\n",
            "Image_nUmber :  31900\n",
            "Image_nUmber :  32000\n",
            "Image_nUmber :  32100\n",
            "Image_nUmber :  32200\n",
            "Image_nUmber :  32300\n",
            "Image_nUmber :  32400\n",
            "Image_nUmber :  32500\n",
            "Image_nUmber :  32600\n",
            "Image_nUmber :  32700\n",
            "Image_nUmber :  32800\n",
            "Image_nUmber :  32900\n",
            "Image_nUmber :  33000\n",
            "Image_nUmber :  33100\n",
            "Image_nUmber :  33200\n",
            "Image_nUmber :  33300\n",
            "Image_nUmber :  33400\n",
            "Image_nUmber :  33500\n",
            "Image_nUmber :  33600\n",
            "Image_nUmber :  33700\n",
            "Image_nUmber :  33800\n",
            "Image_nUmber :  33900\n",
            "Image_nUmber :  34000\n",
            "Image_nUmber :  34100\n",
            "Image_nUmber :  34200\n",
            "Image_nUmber :  34300\n",
            "Image_nUmber :  34400\n",
            "Image_nUmber :  34500\n",
            "Image_nUmber :  34600\n",
            "Image_nUmber :  34700\n",
            "Image_nUmber :  34800\n",
            "Image_nUmber :  34900\n",
            "Image_nUmber :  35000\n",
            "Image_nUmber :  35100\n",
            "Image_nUmber :  35200\n",
            "Image_nUmber :  35300\n",
            "Image_nUmber :  35400\n",
            "Image_nUmber :  35500\n",
            "Image_nUmber :  35600\n",
            "Image_nUmber :  35700\n",
            "Image_nUmber :  35800\n",
            "Image_nUmber :  35900\n",
            "Image_nUmber :  36000\n",
            "Image_nUmber :  36100\n",
            "Image_nUmber :  36200\n",
            "Image_nUmber :  36300\n",
            "Image_nUmber :  36400\n",
            "Image_nUmber :  36500\n",
            "Image_nUmber :  36600\n",
            "Image_nUmber :  36700\n",
            "Image_nUmber :  36800\n",
            "Image_nUmber :  36900\n",
            "Image_nUmber :  37000\n",
            "Image_nUmber :  37100\n",
            "Image_nUmber :  37200\n",
            "Image_nUmber :  37300\n",
            "Image_nUmber :  37400\n",
            "Image_nUmber :  37500\n",
            "Image_nUmber :  37600\n",
            "Image_nUmber :  37700\n",
            "Image_nUmber :  37800\n",
            "Image_nUmber :  37900\n",
            "Image_nUmber :  38000\n",
            "Image_nUmber :  38100\n",
            "Image_nUmber :  38200\n",
            "Image_nUmber :  38300\n",
            "Image_nUmber :  38400\n",
            "Image_nUmber :  38500\n",
            "Image_nUmber :  38600\n",
            "Image_nUmber :  38700\n",
            "Image_nUmber :  38800\n",
            "Image_nUmber :  38900\n",
            "Image_nUmber :  39000\n",
            "Image_nUmber :  39100\n",
            "Image_nUmber :  39200\n",
            "Image_nUmber :  39300\n",
            "Image_nUmber :  39400\n",
            "Image_nUmber :  39500\n",
            "Image_nUmber :  39600\n",
            "Image_nUmber :  39700\n",
            "Image_nUmber :  39800\n",
            "Image_nUmber :  39900\n",
            "Image_nUmber :  40000\n",
            "Image_nUmber :  40100\n",
            "Image_nUmber :  40200\n",
            "Image_nUmber :  40300\n",
            "Image_nUmber :  40400\n",
            "Image_nUmber :  40500\n",
            "Image_nUmber :  40600\n",
            "Image_nUmber :  40700\n",
            "Image_nUmber :  40800\n",
            "Image_nUmber :  40900\n",
            "Image_nUmber :  41000\n",
            "Image_nUmber :  41100\n",
            "Image_nUmber :  41200\n",
            "Image_nUmber :  41300\n",
            "Image_nUmber :  41400\n",
            "Image_nUmber :  41500\n",
            "Image_nUmber :  41600\n",
            "Image_nUmber :  41700\n",
            "Image_nUmber :  41800\n",
            "Image_nUmber :  41900\n",
            "Image_nUmber :  42000\n",
            "Image_nUmber :  42100\n",
            "Image_nUmber :  42200\n",
            "Image_nUmber :  42300\n",
            "Image_nUmber :  42400\n",
            "Image_nUmber :  42500\n",
            "Image_nUmber :  42600\n",
            "Image_nUmber :  42700\n",
            "Image_nUmber :  42800\n",
            "Image_nUmber :  42900\n",
            "Image_nUmber :  43000\n",
            "Image_nUmber :  43100\n",
            "Image_nUmber :  43200\n",
            "Image_nUmber :  43300\n",
            "Image_nUmber :  43400\n",
            "Image_nUmber :  43500\n",
            "Image_nUmber :  43600\n",
            "Image_nUmber :  43700\n",
            "Image_nUmber :  43800\n",
            "Image_nUmber :  43900\n",
            "Image_nUmber :  44000\n",
            "Image_nUmber :  44100\n",
            "Image_nUmber :  44200\n",
            "Image_nUmber :  44300\n",
            "Image_nUmber :  44400\n",
            "Image_nUmber :  44500\n",
            "Image_nUmber :  44600\n",
            "Image_nUmber :  44700\n",
            "Image_nUmber :  44800\n",
            "Image_nUmber :  44900\n",
            "Image_nUmber :  45000\n",
            "Image_nUmber :  45100\n",
            "Image_nUmber :  45200\n",
            "Image_nUmber :  45300\n",
            "Image_nUmber :  45400\n",
            "Image_nUmber :  45500\n",
            "Image_nUmber :  45600\n",
            "Image_nUmber :  45700\n",
            "Image_nUmber :  45800\n",
            "Image_nUmber :  45900\n",
            "Image_nUmber :  46000\n",
            "Image_nUmber :  46100\n",
            "Image_nUmber :  46200\n",
            "Image_nUmber :  46300\n",
            "Image_nUmber :  46400\n",
            "Image_nUmber :  46500\n",
            "Image_nUmber :  46600\n",
            "Image_nUmber :  46700\n",
            "Image_nUmber :  46800\n",
            "Image_nUmber :  46900\n",
            "Image_nUmber :  47000\n",
            "Image_nUmber :  47100\n",
            "Image_nUmber :  47200\n",
            "Image_nUmber :  47300\n",
            "Image_nUmber :  47400\n",
            "Image_nUmber :  47500\n",
            "Image_nUmber :  47600\n",
            "Image_nUmber :  47700\n",
            "Image_nUmber :  47800\n",
            "Image_nUmber :  47900\n",
            "Image_nUmber :  48000\n",
            "Image_nUmber :  48100\n",
            "Image_nUmber :  48200\n",
            "Image_nUmber :  48300\n",
            "Image_nUmber :  48400\n",
            "Image_nUmber :  48500\n",
            "Image_nUmber :  48600\n",
            "Image_nUmber :  48700\n",
            "Image_nUmber :  48800\n",
            "Image_nUmber :  48900\n",
            "Image_nUmber :  49000\n",
            "Image_nUmber :  49100\n",
            "Image_nUmber :  49200\n",
            "Image_nUmber :  49300\n",
            "Image_nUmber :  49400\n",
            "Image_nUmber :  49500\n",
            "Image_nUmber :  49600\n",
            "Image_nUmber :  49700\n",
            "Image_nUmber :  49800\n",
            "Image_nUmber :  49900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save dataset so we won't have to compute it again\n",
        "serialized_dataset_path = '/content/drive/MyDrive/CIFAR10/train.pkl'\n",
        "pickle.dump(train, open(\"df.pkl\", \"wb\"))\n",
        "\n",
        "pickle.dump(test, open(\"df_test.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "3Kvkx9VJ6YWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp df.pkl gdrive/MyDrive/CIFAR10"
      ],
      "metadata": {
        "id": "efptYT2v7UbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp df_test.pkl gdrive/MyDrive/CIFAR10"
      ],
      "metadata": {
        "id": "pLC4A2FQ7jNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to tensor form --> represents the features as one tensor 4D [index, 3, 32, 32]\n",
        "dataset_l  = torch.cat([torch.unsqueeze(tens, 0) for tens in dataset_l])\n",
        "dataset_Z = torch.Tensor.int(output_tensor)\n",
        "\n",
        "#Set up new dataset\n",
        "N_images = 40000\n",
        "train = data_utils.TensorDataset(dataset_l[: N_images], dataset_Z[: N_images])\n",
        "test = data_utils.TensorDataset(dataset_l[N_images:], dataset_Z[N_images: ])"
      ],
      "metadata": {
        "id": "Nsl-Jyt2kCbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load new dataset"
      ],
      "metadata": {
        "id": "ELWhTiQ8-WaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "objects = []\n",
        "with (open(\"/content/gdrive/MyDrive/CIFAR10/df.pkl\", \"rb\")) as openfile:\n",
        "    while True:\n",
        "        try:\n",
        "            objects.append(pickle.load(openfile))\n",
        "        except EOFError:\n",
        "            break\n",
        "\n",
        "with (open(\"/content/gdrive/MyDrive/CIFAR10/df_test.pkl\", \"rb\")) as openfile:\n",
        "    while True:\n",
        "        try:\n",
        "            objects.append(pickle.load(openfile))\n",
        "        except EOFError:\n",
        "            break\n"
      ],
      "metadata": {
        "id": "u0Qnzs8--VxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = objects[0]\n",
        "test = objects[1]"
      ],
      "metadata": {
        "id": "T06z8lNZ_QkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computation of $\\vec{w}$"
      ],
      "metadata": {
        "id": "EhmuNvwY2TLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Store indeces as tensor\n",
        "\n",
        "position_tensor = torch.zeros([len(hist_obj[1][:-1]), len(hist_obj[2][:-1])] )\n",
        "for position, index in zip(positions, indeces):\n",
        "  position_tensor[position[0], position[1]] = index\n",
        "\n",
        "position_tensor = torch.Tensor.int(position_tensor)\n",
        "\n",
        "auxiliary_tensor = torch.tensor([i for i in range(Q)], requires_grad = False)\n",
        "auxiliary_tensor = torch.unsqueeze(auxiliary_tensor, 0)\n",
        "auxiliary_tensor = torch.unsqueeze(auxiliary_tensor, 0)\n",
        "auxiliary_tensor = torch.Tensor.repeat(auxiliary_tensor, [32, 32, 1])\n",
        "auxiliary_tensor = torch.unsqueeze(auxiliary_tensor, 0)\n",
        "auxiliary_tensor = torch.permute(auxiliary_tensor, [0,3,1,2])"
      ],
      "metadata": {
        "id": "msjCZnYqAGfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = .5                                  # lambda\n",
        "p = np.ndarray.flatten(hist_obj[0])\n",
        "p = p[p > 0.]                           # p is a 1D array with the non-zero probabilities\n",
        "Q = len(p)\n",
        "\n",
        "w = 1 / ((1-l)*p + l/Q)\n",
        "w = w / np.dot(w , p)"
      ],
      "metadata": {
        "id": "f5wDYh1H1vxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define loss function\n",
        "\n",
        "$L_{cl} = - \\sum_{h,w, q} v(Z_{hw}) Z_{h,w,q}\\log(\\hat{Z}_{hwq})$, $v(Z_{hw}) = w_{q^*}$, where $q^*$ is the index of the corresponding bin. We encode the ground truth $Z_{h,w,q}$ using one-hot-encoding.\n",
        "\n",
        "*Reminder: Z has the shape of (1, h, w, q)*."
      ],
      "metadata": {
        "id": "E4FXecvx4uuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training (special loss)\n",
        "\n",
        "Potremmo salvare un'unica volta il dataset nella forma (ndati, 1, 32, 32). Per la loss dobbiamo fare una cross entropy tra i due"
      ],
      "metadata": {
        "id": "iDXfUaX0RvrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data loader\n",
        "batch_size = 200\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "ZFYhStjwSu7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(w)\n",
        "w = w.clone().detach()\n",
        "\n",
        "def mylog(tensor):\n",
        "  eps = 1e-50\n",
        "  new_tensor = torch.clone(tensor)\n",
        "  new_tensor[tensor <= 0.] = eps\n",
        "  return torch.log(new_tensor)"
      ],
      "metadata": {
        "id": "W5dkIrnY4pA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c56eba1-ab3f-435d-c00e-168cad6a1cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-621382bdcf67>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  w = torch.tensor(w)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class network_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(network_model, self).__init__()\n",
        "\n",
        "    resnet = models.resnet18(weights = \"IMAGENET1K_V1\")\n",
        "    self.resnet_base = nn.Sequential(*list(resnet.children())[0:6]) #first 6 layers of resnet, which end with 128 channels\n",
        "\n",
        "    for param in self.resnet_base.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "\n",
        "    # define our layers on top of resnet\n",
        "    self.cnn_next = nn.Sequential(\n",
        "      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.Upsample(scale_factor=4),\n",
        "      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.Upsample(scale_factor=2),\n",
        "      nn.Conv2d(64, Q, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(Q),\n",
        "      nn.ReLU(),\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    y = self.resnet_base(input) #first go through resnet\n",
        "    z = self.cnn_next(y)        #then go through our layers\n",
        "    return z"
      ],
      "metadata": {
        "id": "Wtl4vQtURvR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, Z_pred, Z_truth):\n",
        "      nData = Z_pred.shape[0]\n",
        "      v = w[Z_truth].view(nData, 32, 32)\n",
        "\n",
        "      zeros = torch.zeros(nData, Q, 32, 32)\n",
        "      one_hot = zeros.scatter(1, Z_truth.type(torch.int64), v)\n",
        "\n",
        "      l = -torch.sum(v*torch.sum(one_hot * mylog(Z_pred), dim = 1), [0,1,2])\n",
        "\n",
        "      return l"
      ],
      "metadata": {
        "id": "WY73m_IoR0lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = network_model() #CNN\n",
        "loss = nn.CrossEntropyLoss()       #We begin with a simple MSE loss function\n",
        "optim = torch.optim.Adam(network.parameters(), lr=1e-4, weight_decay=0.0)"
      ],
      "metadata": {
        "id": "RToPVW0ESTuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses_train = []\n",
        "losses_val = []\n",
        "\n",
        "epochs = 50\n",
        "patience = 8 #how many epochs of non decreasing validation we accept\n",
        "min_val = 0 #minimum validation loss (initialized to a meaningless value - we will update it at the first epoch)\n",
        "softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "with torch.autograd.set_detect_anomaly(False):\n",
        "  for epoch in range(epochs):\n",
        "    print(\"Epoch \", epoch)\n",
        "    network.train() #Set it up for training\n",
        "    i = 0\n",
        "    ls = []\n",
        "    for features, labels in train_loader:\n",
        "      predictions = network(features)\n",
        "      predictions_sm = softmax(predictions)\n",
        "\n",
        "      v = w[labels].view(batch_size, 32, 32)\n",
        "      zeros = torch.zeros(batch_size, Q, 32, 32, dtype = torch.float64)\n",
        "\n",
        "      one_hot = zeros.scatter(dim = 1, index = labels.type(torch.int64), src = torch.unsqueeze(v, 1))\n",
        "      L = loss(predictions_sm, one_hot)\n",
        "      ls.append(L.item())\n",
        "\n",
        "      optim.zero_grad()\n",
        "      L.backward()\n",
        "      optim.step()\n",
        "\n",
        "      if i%20 == 0:\n",
        "        print(\"Loss at iteration \",  i , \" is \", L.item())\n",
        "      i += 1\n",
        "    losses_train.append(mean(ls))\n",
        "\n",
        "    #Validation loss\n",
        "    network.eval()\n",
        "    with torch.no_grad():\n",
        "      val_batches = []\n",
        "      for features, labels in test_loader:\n",
        "        prediction_val = network(features)\n",
        "        prediction_val_sm = softmax(prediction_val.clone())\n",
        "\n",
        "        v = w[labels].view(batch_size, 32, 32)\n",
        "        zeros = torch.zeros(batch_size, Q, 32, 32, dtype = torch.float64)\n",
        "\n",
        "        one_hot = zeros.scatter(dim = 1, index = labels.type(torch.int64), src = torch.unsqueeze(v, 1))\n",
        "\n",
        "        val_loss = loss(prediction_val_sm, one_hot)\n",
        "        val_batches.append(val_loss.item())\n",
        "      print(\"At epoch \", epoch, \" validation loss \", mean(val_batches))\n",
        "      losses_val.append(mean(val_batches))\n",
        "\n",
        "    #Early stopping\n",
        "    if epoch == 1:\n",
        "      min_val = mean(val_batches)\n",
        "\n",
        "    if mean(val_batches) < min_val:\n",
        "      min_val = mean(val_batches)\n",
        "\n",
        "    #Early stopping: break if no new minimum was reached in the last *patience* epochs\n",
        "\n",
        "    if epoch >= patience:\n",
        "        condition = 0\n",
        "        for index in range(patience):\n",
        "          if losses_val[-(index + 1)] > min_val:\n",
        "            condition += 1\n",
        "        if condition == patience:\n",
        "          print(\"Early stopping!\")\n",
        "          break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "nlGfqfWHSc7-",
        "outputId": "9769ee3b-bd58-47ad-eec0-0019ff4b4547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0\n",
            "Loss at iteration  0  is  6.359157626721423e-08\n",
            "Loss at iteration  20  is  6.784163816128598e-08\n",
            "Loss at iteration  40  is  7.725445569654336e-08\n",
            "Loss at iteration  60  is  8.366441493190816e-08\n",
            "Loss at iteration  80  is  6.278760866897153e-08\n",
            "Loss at iteration  100  is  2.6166216673177865e-07\n",
            "Loss at iteration  120  is  1.3008213315677793e-07\n",
            "Loss at iteration  140  is  1.9076777853611785e-07\n",
            "Loss at iteration  160  is  6.943666216542439e-08\n",
            "Loss at iteration  180  is  6.420888368150975e-08\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "only batches of spatial targets supported (3D tensors) but got targets of dimension: 4",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-4d11ff308276>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprediction_val_sm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_val_sm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mval_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At epoch \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" validation loss \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of dimension: 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CRmHNcDT8edC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}